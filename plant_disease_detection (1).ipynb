{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "UijyLtSuvTXn",
        "outputId": "28ccc6fc-4e57-4dca-dd7e-899622645aaa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f28c905-0f20-42ac-b8c2-0f9dca11cac8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4f28c905-0f20-42ac-b8c2-0f9dca11cac8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "ref                                                            title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "muhammadehsan000/healthcare-dataset-2019-2024                  Healthcare Dataset (2019-2024)                       3MB  2024-08-09 17:52:25           3339         76  1.0              \n",
            "berkayalan/paris-2024-olympics-medals                          Paris 2024 Olympics Medals                           1KB  2024-08-14 11:02:45           1331         33  1.0              \n",
            "parthdande/movies-box-office-collection-data-2000-2024         Movies Box Office Collection Data 2000-2024        161KB  2024-08-15 07:31:34            713         21  1.0              \n",
            "souradippal/student-performance-prediction                     Student Performance Prediction                     381KB  2024-08-16 15:59:38            564         21  1.0              \n",
            "arpit2712/amazonsalesreport                                    AmazonSalesReport                                    3MB  2024-08-07 19:15:47           1848         31  1.0              \n",
            "muhammadehsan000/global-electric-vehicle-sales-data-2010-2024  Global Electric Vehicle Sales Data (2010-2024)      83KB  2024-08-09 16:39:22           2194         43  1.0              \n",
            "emreksz/software-engineer-jobs-and-salaries-2024               Software Engineer Jobs & Salaries 2024              23KB  2024-08-12 00:08:03           1256         30  1.0              \n",
            "myrios/cost-of-living-index-by-country-by-number-2024          Cost of Living Index by Country                      3KB  2024-07-19 06:25:42           5539         85  1.0              \n",
            "waqi786/heart-attack-dataset                                   ❤️ Heart Attack Risk Factors Dataset                 9KB  2024-08-06 10:57:42           2435         38  1.0              \n",
            "muhammadehsan000/olympic-historical-dataset-1896-2020          Olympic Historical Dataset (1896 - 2022)            27MB  2024-08-06 16:46:08           3080         65  1.0              \n",
            "krishujeniya/heart-diseae                                      Heart Disease Prediction Dataset                     3KB  2024-07-28 14:46:19           1622         35  1.0              \n",
            "jenilhareshbhaighori/real-world-laptop-data-analysis           Real world Laptop Data Analysis                      1MB  2024-08-11 10:27:08            370         27  1.0              \n",
            "sajkazmi/paris-olympics-2024-games-dataset-updated-daily       Paris Olympics 2024 Games Dataset (updated daily)    6MB  2024-08-13 02:25:23           1422         36  0.8235294        \n",
            "youssefismail20/olympic-games-1994-2024                        Olympic Games (1994-2024) 🏅🌍                        16KB  2024-08-11 20:19:04           2623         44  1.0              \n",
            "piterfm/paris-2024-olympic-summer-games                        Paris 2024 Olympic Summer Games                      3MB  2024-08-18 23:15:17           7810        174  1.0              \n",
            "mrmars1010/flipkart-product-datalaptops                        Flipkart Sales Dataset(Laptops)                      6MB  2024-08-11 03:44:59           1221         28  0.88235295       \n",
            "krupalpatel07/tesla-stock-data                                 Tesla Stock Data                                    94KB  2024-08-05 09:34:31            733         17  1.0              \n",
            "x1akshay/car-dataset                                           Car Dataset                                          1KB  2024-07-25 06:41:55           1250         25  1.0              \n",
            "waqi786/powerlifting-data                                      🏋️ Powerlifting Data                                17KB  2024-08-01 10:18:50           1101         28  1.0              \n",
            "raminhuseyn/dataset-from-tiktok                                Dataset from TikTok                                794KB  2024-07-27 19:14:02           1492         26  1.0              \n"
          ]
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8k6T6bEvi7V",
        "outputId": "33071bdd-1728-4615-89f7-174196242ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading new-plant-diseases-dataset.zip to /content\n",
            "100% 2.70G/2.70G [02:06<00:00, 23.8MB/s]\n",
            "100% 2.70G/2.70G [02:06<00:00, 23.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/new-plant-diseases-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "fEM8LXKcv8ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "# from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from keras.layers import Convolution2D,Dense,MaxPool2D,Activation,Dropout,Flatten\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D"
      ],
      "metadata": {
        "id": "QdpwJUAXwc9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Test-Train Data\n",
        "Split the dataset\n",
        "\n",
        "os.walk()-->This function gives the possibility to list the contents of a directory. For example, it is used to find out which files and subdirectories are in the current directory.'''\n",
        "def get_files(directory):\n",
        "  if not os.path.exists(directory):\n",
        "    return 0\n",
        "  count=0\n",
        "  # crawls inside folders\n",
        "  for current_path,dirs,files in os.walk(directory):\n",
        "    for dr in dirs:\n",
        "      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n",
        "  return count\n",
        "train_dir =\"/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
        "test_dir=\"/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\""
      ],
      "metadata": {
        "id": "vuy73XHOwk52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#glob.glob()-->It is a module that helps to list files in a specific folder in Python. Searches in subfolders.\n",
        "\n",
        " #train file image count\n",
        "train_samples =get_files(train_dir)\n",
        "#to get tags\n",
        "num_classes=len(glob.glob(train_dir+\"/*\"))\n",
        "#test file image count\n",
        "test_samples=get_files(test_dir)\n",
        "print(num_classes,\"Classes\")\n",
        "print(train_samples,\"Train images\")\n",
        "print(test_samples,\"Test images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsJf3bZMxDMo",
        "outputId": "c88f5365-7a88-43ae-eda1-5027b11df0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38 Classes\n",
            "70295 Train images\n",
            "17572 Test images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''1.3. ImageDataGenerator\n",
        "ImageDataGenerator,Data augmentation is used to increase the size of training set and to get more different image. Through Data augmentation we can prevent overfitting ,this refers to randomly changing the images in ways that shouldn’t impact their interpretation, such as horizontal flipping, zooming, and rotating\n",
        "\n",
        "Rescale: One of the many magnification parameters adjusts the pixel values of our image.\n",
        "Shear_range: counterclockwise shear angle in degrees\n",
        "Zoom_range: zoom\n",
        "Horizontal_flip: flip image horizontally\n",
        "Do not perform augmentation on validation and test data/validation set ,this might mislead the results'''\n",
        "\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        "    )\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "2b4UM_4PxM27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''flow_from_directory() --> Another method to read images into TensorFlow environment is to use the .flow_from_directory() method. flow_from_directory is an ImageDataGenerator method. The dataset is read with flow_from_directory without making any changes.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "directory: The path of the target directory. It must contain one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF formatted images found in each of the subdirectories will be included in the generator.\n",
        "target_size: A tuple of integers, (height, width), by default (256,256). All found images will be resized.\n",
        "batch_size: The size of the data chunks (default: 32).\n",
        "shuffle: Decides whether to shuffle data (default: True). If set to false, it sorts the data in alphanumeric order.'''\n",
        "\n",
        "input_shape=(224,224,3)\n",
        "train_generator =train_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=32)\n",
        "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=True,target_size=(224,224),batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yjfp4GwxVEH",
        "outputId": "cca260d3-154e-41c2-ede2-0516935622a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 70295 images belonging to 38 classes.\n",
            "Found 17572 images belonging to 38 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''AlexNet\n",
        "This deep convolutional neural network consisting of 25 layers consists of 5 convolution layers, 3 maxpool layers, 2 dropout layers, 3 fully connected layers, 7 relu layers, 2 normalization layers, softmax layer, input and classification (output) layers. .'''\n",
        "\n",
        "# Importing Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "4jeyy8UhxeyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the CNN\n",
        "model = Sequential()\n",
        "# Convolution Step 1\n",
        "model.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=(224, 224, 3), activation = 'relu'))\n",
        "# Max Pooling Step 1\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model.add(BatchNormalization())\n",
        "# Convolution Step 2\n",
        "model.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n",
        "# Max Pooling Step 2\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "# Convolution Step 3\n",
        "model.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "# Convolution Step 4\n",
        "model.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "# Convolution Step 5\n",
        "model.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n",
        "# Max Pooling Step 3\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model.add(BatchNormalization())\n",
        "# Flattening Step\n",
        "model.add(Flatten())\n",
        "# Full Connection Step\n",
        "model.add(Dense(units = 4096, activation = 'relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units = 4096, activation = 'relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units = 1000, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units = num_classes, activation = 'softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FzHQY8VSxmsc",
        "outputId": "32fbd739-d881-4325-9926-e8b29d564364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │          \u001b[38;5;34m34,944\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m2,973,952\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m384\u001b[0m)           │         \u001b[38;5;34m885,120\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m384\u001b[0m)           │           \u001b[38;5;34m1,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)           │       \u001b[38;5;34m1,327,488\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)           │           \u001b[38;5;34m1,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m884,992\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │       \u001b[38;5;34m1,052,672\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │          \u001b[38;5;34m16,384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │      \u001b[38;5;34m16,781,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │          \u001b[38;5;34m16,384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │       \u001b[38;5;34m4,097,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │           \u001b[38;5;34m4,000\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)                  │          \u001b[38;5;34m38,038\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,973,952</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,672</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,097,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,038</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,117,790\u001b[0m (107.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,117,790</span> (107.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,096,654\u001b[0m (107.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,096,654</span> (107.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,136\u001b[0m (82.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,136</span> (82.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "                       test_dir,\n",
        "                       target_size=(224, 224),\n",
        "                       batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB4R7lbTxqw8",
        "outputId": "f303c0e8-a204-4231-e97e-0756b7dd2a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17572 images belonging to 38 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=None,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=4,\n",
        "    verbose=1,\n",
        "    callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.3,patience=3, min_lr=0.000001)],\n",
        "    shuffle=True)"
      ],
      "metadata": {
        "id": "OJ80Vevvx17t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f41270-dc0c-4d0b-ffc0-97cfad278032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m899s\u001b[0m 400ms/step - accuracy: 0.3048 - loss: 2.6250 - val_accuracy: 0.6328 - val_loss: 1.2637 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m886s\u001b[0m 390ms/step - accuracy: 0.6694 - loss: 1.0704 - val_accuracy: 0.7188 - val_loss: 0.9759 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 390ms/step - accuracy: 0.7770 - loss: 0.7109 - val_accuracy: 0.5078 - val_loss: 2.7214 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 405ms/step - accuracy: 0.8286 - loss: 0.5481 - val_accuracy: 0.5469 - val_loss: 1.6855 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m906s\u001b[0m 411ms/step - accuracy: 0.8639 - loss: 0.4326 - val_accuracy: 0.7891 - val_loss: 0.8119 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m905s\u001b[0m 410ms/step - accuracy: 0.8812 - loss: 0.3722 - val_accuracy: 0.7812 - val_loss: 0.8552 - learning_rate: 0.0010\n",
            "Epoch 7/15\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m916s\u001b[0m 415ms/step - accuracy: 0.8971 - loss: 0.3203 - val_accuracy: 0.8281 - val_loss: 0.6446 - learning_rate: 0.0010\n",
            "Epoch 8/15\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m929s\u001b[0m 421ms/step - accuracy: 0.9087 - loss: 0.2806 - val_accuracy: 0.8750 - val_loss: 0.3863 - learning_rate: 0.0010\n",
            "Epoch 9/15\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m955s\u001b[0m 433ms/step - accuracy: 0.9181 - loss: 0.2432 - val_accuracy: 0.5469 - val_loss: 2.0354 - learning_rate: 0.0010\n",
            "Epoch 10/15\n",
            "\u001b[1m 485/2197\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:01\u001b[0m 527ms/step - accuracy: 0.9233 - loss: 0.2290"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('C:/Users/Sameervali Mohammad/OneDrive/Desktop/pro/trained_models/model__Alexnet.h5')"
      ],
      "metadata": {
        "id": "C9EKSQAcx7aN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "c5080adb-fcc0-4d18-a1c2-da16050af7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d0c493a4a27e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Users/Sameervali Mohammad/OneDrive/Desktop/pro/trained_models/model__Alexnet.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model_alexnet.evaluate(validation_generator)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "metadata": {
        "id": "gq3u9yAJx903"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_alexnet.evaluate(test_generator, verbose=1)\n",
        "\n",
        "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "id": "NYIe1JSex-g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label of the test_gen\n",
        "pred = model.predict(test_generator,verbose=1)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "# Map the label\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]"
      ],
      "metadata": {
        "id": "DKS9oiQ_yAi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = list(train_generator.Label)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "OdLR4wPNyCRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "\n",
        "print(history5.history.keys())\n",
        "\n",
        "plt.plot(history5.history['accuracy'])\n",
        "plt.plot(history5.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history5.history['loss'])\n",
        "plt.plot(history5.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Id4z5N29yGUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AlexNet Model\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "model_alexnet=load_model('/content/drive/MyDrive/Colab Notebooks/Model/plant_disease_alexnet2.h5')"
      ],
      "metadata": {
        "id": "LiDf_H6LyHEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=list(train_generator.class_indices.keys())\n",
        "# Pre-Processing test data same as train data.\n",
        "def prepare(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224,224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "img_url='/content/drive/MyDrive/Colab Notebooks/dataset/plant__leaf/val/Apple__Healthy/78e648c6-a360-4fa8-b8ab-1225b164b7fd___RS_HL 7243.JPG'\n",
        "result_alexnet = model_alexnet.predict([prepare(img_url)])\n",
        "disease=image.load_img(img_url)\n",
        "plt.imshow(disease)\n",
        "\n",
        "classresult=np.argmax(result_alexnet,axis=1)\n",
        "print(classes[classresult[0]])"
      ],
      "metadata": {
        "id": "2ZKfa92byReU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}