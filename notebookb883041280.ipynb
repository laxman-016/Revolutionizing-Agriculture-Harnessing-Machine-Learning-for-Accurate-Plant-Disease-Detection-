{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import libraries\n\nimport os\nimport cv2\nimport glob\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.preprocessing import image\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n# from tensorflow.keras.applications.vgg16 import VGG16\n# from tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# from tensorflow.keras.applications.inception_v3 import InceptionV3\n# from tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom keras.layers import Convolution2D,Dense,MaxPool2D,Activation,Dropout,Flatten\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D","metadata":{"id":"QdpwJUAXwc9N","execution":{"iopub.status.busy":"2024-08-19T11:27:50.182698Z","iopub.execute_input":"2024-08-19T11:27:50.182970Z","iopub.status.idle":"2024-08-19T11:28:05.059204Z","shell.execute_reply.started":"2024-08-19T11:27:50.182945Z","shell.execute_reply":"2024-08-19T11:28:05.058407Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-19 11:27:53.702347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-19 11:27:53.702477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-19 11:27:53.881084: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"'''Test-Train Data\nSplit the dataset\n\nos.walk()-->This function gives the possibility to list the contents of a directory. For example, it is used to find out which files and subdirectories are in the current directory.'''\ndef get_files(directory):\n  if not os.path.exists(directory):\n    return 0\n  count=0\n  # crawls inside folders\n  for current_path,dirs,files in os.walk(directory):\n    for dr in dirs:\n      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n  return count\ntrain_dir =\"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\ntest_dir=\"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"","metadata":{"id":"vuy73XHOwk52","execution":{"iopub.status.busy":"2024-08-19T11:28:22.519014Z","iopub.execute_input":"2024-08-19T11:28:22.520170Z","iopub.status.idle":"2024-08-19T11:28:22.527878Z","shell.execute_reply.started":"2024-08-19T11:28:22.520116Z","shell.execute_reply":"2024-08-19T11:28:22.526854Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#glob.glob()-->It is a module that helps to list files in a specific folder in Python. Searches in subfolders.\n\n #train file image count\ntrain_samples =get_files(train_dir)\n#to get tags\nnum_classes=len(glob.glob(train_dir+\"/*\"))\n#test file image count\ntest_samples=get_files(test_dir)\nprint(num_classes,\"Classes\")\nprint(train_samples,\"Train images\")\nprint(test_samples,\"Test images\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jsJf3bZMxDMo","outputId":"57391429-8989-4878-b501-6225b4b85739","execution":{"iopub.status.busy":"2024-08-19T11:28:31.038662Z","iopub.execute_input":"2024-08-19T11:28:31.039006Z","iopub.status.idle":"2024-08-19T11:29:23.213389Z","shell.execute_reply.started":"2024-08-19T11:28:31.038979Z","shell.execute_reply":"2024-08-19T11:29:23.212483Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"38 Classes\n70295 Train images\n17572 Test images\n","output_type":"stream"}]},{"cell_type":"code","source":"'''1.3. ImageDataGenerator\nImageDataGenerator,Data augmentation is used to increase the size of training set and to get more different image. Through Data augmentation we can prevent overfitting ,this refers to randomly changing the images in ways that shouldn’t impact their interpretation, such as horizontal flipping, zooming, and rotating\n\nRescale: One of the many magnification parameters adjusts the pixel values of our image.\nShear_range: counterclockwise shear angle in degrees\nZoom_range: zoom\nHorizontal_flip: flip image horizontally\nDo not perform augmentation on validation and test data/validation set ,this might mislead the results'''\n\ntrain_datagen=ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n    )\ntest_datagen=ImageDataGenerator(rescale=1./255)","metadata":{"id":"2b4UM_4PxM27","execution":{"iopub.status.busy":"2024-08-19T11:29:29.389466Z","iopub.execute_input":"2024-08-19T11:29:29.389810Z","iopub.status.idle":"2024-08-19T11:29:29.395386Z","shell.execute_reply.started":"2024-08-19T11:29:29.389783Z","shell.execute_reply":"2024-08-19T11:29:29.394583Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"'''flow_from_directory() --> Another method to read images into TensorFlow environment is to use the .flow_from_directory() method. flow_from_directory is an ImageDataGenerator method. The dataset is read with flow_from_directory without making any changes.\n\nParameters:\n\ndirectory: The path of the target directory. It must contain one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF formatted images found in each of the subdirectories will be included in the generator.\ntarget_size: A tuple of integers, (height, width), by default (256,256). All found images will be resized.\nbatch_size: The size of the data chunks (default: 32).\nshuffle: Decides whether to shuffle data (default: True). If set to false, it sorts the data in alphanumeric order.'''\n\ninput_shape=(224,224,3)\ntrain_generator =train_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=32)\ntest_generator=test_datagen.flow_from_directory(test_dir,shuffle=True,target_size=(224,224),batch_size=32)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Yjfp4GwxVEH","outputId":"e7729fa8-9ec5-4ff4-c565-3fedf28e95f2","execution":{"iopub.status.busy":"2024-08-19T11:29:42.892932Z","iopub.execute_input":"2024-08-19T11:29:42.893280Z","iopub.status.idle":"2024-08-19T11:29:55.668240Z","shell.execute_reply.started":"2024-08-19T11:29:42.893253Z","shell.execute_reply":"2024-08-19T11:29:55.667368Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 70295 images belonging to 38 classes.\nFound 17572 images belonging to 38 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"'''AlexNet\nThis deep convolutional neural network consisting of 25 layers consists of 5 convolution layers, 3 maxpool layers, 2 dropout layers, 3 fully connected layers, 7 relu layers, 2 normalization layers, softmax layer, input and classification (output) layers. .'''\n\n# Importing Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization","metadata":{"id":"4jeyy8UhxeyO","execution":{"iopub.status.busy":"2024-08-19T11:30:01.237920Z","iopub.execute_input":"2024-08-19T11:30:01.238284Z","iopub.status.idle":"2024-08-19T11:30:01.243664Z","shell.execute_reply.started":"2024-08-19T11:30:01.238257Z","shell.execute_reply":"2024-08-19T11:30:01.242655Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Initializing the CNN\nmodel = Sequential()\n# Convolution Step 1\nmodel.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=(224, 224, 3), activation = 'relu'))\n# Max Pooling Step 1\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\nmodel.add(BatchNormalization())\n# Convolution Step 2\nmodel.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n# Max Pooling Step 2\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\nmodel.add(BatchNormalization())\n# Convolution Step 3\nmodel.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nmodel.add(BatchNormalization())\n# Convolution Step 4\nmodel.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nmodel.add(BatchNormalization())\n# Convolution Step 5\nmodel.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n# Max Pooling Step 3\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\nmodel.add(BatchNormalization())\n# Flattening Step\nmodel.add(Flatten())\n# Full Connection Step\nmodel.add(Dense(units = 4096, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units = 4096, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units = 1000, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units = num_classes, activation = 'softmax'))\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FzHQY8VSxmsc","outputId":"12247f72-c9cb-4d5f-c449-a34094e6ebb7","execution":{"iopub.status.busy":"2024-08-19T11:30:04.848617Z","iopub.execute_input":"2024-08-19T11:30:04.848972Z","iopub.status.idle":"2024-08-19T11:30:06.155492Z","shell.execute_reply.started":"2024-08-19T11:30:04.848945Z","shell.execute_reply":"2024-08-19T11:30:06.154624Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m34,944\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │           \u001b[38;5;34m384\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m2,973,952\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │       \u001b[38;5;34m885,120\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │         \u001b[38;5;34m1,536\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │     \u001b[38;5;34m1,327,488\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │         \u001b[38;5;34m1,536\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m884,992\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │     \u001b[38;5;34m1,052,672\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │        \u001b[38;5;34m16,384\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │        \u001b[38;5;34m16,384\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │     \u001b[38;5;34m4,097,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │         \u001b[38;5;34m4,000\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)             │        \u001b[38;5;34m38,038\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,973,952</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,672</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,097,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,038</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,117,790\u001b[0m (107.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,117,790</span> (107.26 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,096,654\u001b[0m (107.18 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,096,654</span> (107.18 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,136\u001b[0m (82.56 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,136</span> (82.56 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"validation_generator = train_datagen.flow_from_directory(\n                       test_dir,\n                       target_size=(224, 224),\n                       batch_size=32)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EB4R7lbTxqw8","outputId":"b1a2ebed-2dd8-4eff-ca6f-68944fda1a99","execution":{"iopub.status.busy":"2024-08-19T11:30:13.529857Z","iopub.execute_input":"2024-08-19T11:30:13.530824Z","iopub.status.idle":"2024-08-19T11:30:14.424165Z","shell.execute_reply.started":"2024-08-19T11:30:13.530792Z","shell.execute_reply":"2024-08-19T11:30:14.423442Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 17572 images belonging to 38 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compile model\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\n# Callbacks\ncheckpoint = ModelCheckpoint(\n    'best_model.keras',\n    monitor='val_loss',\n    save_best_only=True,\n    mode='min',\n    verbose=1\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.3,\n    patience=3,\n    min_lr=0.000001,\n    verbose=1\n)\n\n# Train model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=None,\n    epochs=15,\n    validation_data=validation_generator,\n    validation_steps=4,\n    verbose=1,\n    callbacks=[checkpoint, reduce_lr],\n    shuffle=True\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNdaq9DR-tH3","outputId":"0187624c-98d0-4430-e87a-efd6b8892a8e","execution":{"iopub.status.busy":"2024-08-19T11:34:47.521516Z","iopub.execute_input":"2024-08-19T11:34:47.522098Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   2/2197\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 55ms/step - accuracy: 0.0703 - loss: 4.5763   ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1724067314.048879     121 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1724067314.073941     121 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 445/2197\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:58\u001b[0m 582ms/step - accuracy: 0.1552 - loss: 3.4869","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the best model saved so far\nmodel = load_model('best_model.keras')\n\n# Continue training from where it left off\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=None,\n    epochs=15,  # Adjust this based on where it stopped\n    validation_data=validation_generator,\n    validation_steps=4,\n    callbacks=[checkpoint, reduce_lr],\n    verbose=1,\n    shuffle=True\n)","metadata":{"id":"9j2Fjbi7-70r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('C:/Users/Sameervali Mohammad/OneDrive/Desktop\\pro/trained_models/model__Alexnet.keras')","metadata":{"id":"C9EKSQAcx7aN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"[INFO] Calculating model accuracy\")\nscores = model_alexnet.evaluate(validation_generator)\nprint(f\"Test Accuracy: {scores[1]*100}\")","metadata":{"id":"gq3u9yAJx903"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model_alexnet.evaluate(test_generator, verbose=1)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"id":"NYIe1JSex-g4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the label of the test_gen\npred = model.predict(test_generator,verbose=1)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]","metadata":{"id":"DKS9oiQ_yAi4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = list(train_generator.Label)\nprint(classification_report(y_test, pred))","metadata":{"id":"OdLR4wPNyCRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nimport matplotlib.pyplot as plt\nimport numpy\n\nprint(history5.history.keys())\n\nplt.plot(history5.history['accuracy'])\nplt.plot(history5.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history5.history['loss'])\nplt.plot(history5.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"id":"Id4z5N29yGUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AlexNet Model\n\nimport numpy as np\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nmodel_alexnet=load_model('C:/Users/sunke vamshi krishna/OneDrive - Vasavi College Of Engineering/Desktop/sameer/model__Alexnet.keras')","metadata":{"id":"LiDf_H6LyHEa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes=list(train_generator.class_indices.keys())\n# Pre-Processing test data same as train data.\ndef prepare(img_path):\n    img = image.load_img(img_path, target_size=(224,224))\n    x = image.img_to_array(img)\n    x = x/255\n    return np.expand_dims(x, axis=0)\n\nimg_url='/content/drive/MyDrive/Colab Notebooks/dataset/plant__leaf/val/Apple__Healthy/78e648c6-a360-4fa8-b8ab-1225b164b7fd___RS_HL 7243.JPG'\nresult_alexnet = model_alexnet.predict([prepare(img_url)])\ndisease=image.load_img(img_url)\nplt.imshow(disease)\n\nclassresult=np.argmax(result_alexnet,axis=1)\nprint(classes[classresult[0]])","metadata":{"id":"2ZKfa92byReU"},"execution_count":null,"outputs":[]}]}